import torch
import torch.nn as nn
import numpy as np

# Define the PINN class exactly as in burgers1d_pytorch_model_and_data_generator.py
class PINN(nn.Module):
    def __init__(self, layers):
        super().__init__()
        net_layers = []
        for i in range(len(layers) - 2):
            net_layers.append(nn.Linear(layers[i], layers[i+1]))
            net_layers.append(nn.Tanh())
        net_layers.append(nn.Linear(layers[-2], layers[-1]))
        self.net = nn.Sequential(*net_layers)

    def forward(self, x):
        return self.net(x)

# Define the BurgersPINN class as it was in generate_torchscript_model.py for training
class BurgersPINN(nn.Module):
    def __init__(self, layers):
        super().__init__()
        self.inference_net = PINN(layers)
        self.register_buffer('nu', torch.tensor(0.01 / np.pi))

    def forward(self, x_f, x0_cat, xb_left_cat, xb_right_cat):
        # This forward method is for training, but we need it to load the model
        return self.inference_net(x_f) # Dummy return, actual logic is in loss

# Define the layers based on burgers1d_pytorch_model_and_data_generator.py
layers = [2, 10, 10, 10, 10, 10, 10, 10, 10, 1]

# Load the Fortran-trained model (which is a BurgersPINN instance)
model_path = "burgers_model_trained.pt"

# Instantiate BurgersPINN with the correct layers
# We need to load it as a ScriptModule, then access its inference_net
trained_model_full = torch.jit.load(model_path)

# Extract the inference_net (which is the PINN part)
inference_pinn = trained_model_full.inference_net

# Set to evaluation mode
inference_pinn.eval()

# Load the XT_tensor from python_xt_tensor.bin (generated by original Python script)
with open("python_xt_tensor.bin", 'rb') as f:
    XT_tensor_flat = np.fromfile(f, dtype=np.float32)
    XT_tensor_np = XT_tensor_flat.reshape(-1, 2) # Reshape to (N, features)

# Convert to PyTorch tensor and move to device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
XT_tensor = torch.tensor(XT_tensor_np, dtype=torch.float32).to(device)

# Perform inference using the Fortran-trained PINN model
with torch.no_grad():
    u_pred_fortran_trained_python_inference = inference_pinn(XT_tensor).cpu().numpy()

# Reshape u_pred to (N_t, N_x) for saving
N_x = 256 # Hardcoded from burgers1d_pytorch_model_and_data_generator.py
N_t = 100 # Hardcoded from burgers1d_pytorch_model_and_data_generator.py
u_pred_reshaped = u_pred_fortran_trained_python_inference.reshape(N_t, N_x)

# Save results to a binary file
output_filename = "fortran_trained_model_python_inference_results.bin"
with open(output_filename, 'wb') as f:
    f.write(np.array([N_x, N_t], dtype=np.int32).tobytes())
    f.write(np.linspace(-1.0, 1.0, N_x).astype(np.float32).tobytes()) # x_grid
    f.write(np.linspace(0.0, 1.0, N_t).astype(np.float32).tobytes())  # t_grid
    f.write(u_pred_reshaped.astype(np.float32).tobytes())

print(f"Fortran-trained model's Python inference results saved to {output_filename}")
