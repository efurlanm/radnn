{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8804aa1f-b79c-463a-9e61-1437afb23470",
   "metadata": {},
   "source": [
    "# Several tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bed626e-6b5d-4c88-b5a6-efa1176b9631",
   "metadata": {},
   "source": [
    "## repository/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c42f2b-ed57-40e5-8b4a-5cbe32c1b562",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile CMakeLists.txt\n",
    "# Define the minimum required CMake version. Version 3.17 is specified in the parent CMakeLists.txt\n",
    "# for FindCUDAToolkit support, so we keep this.\n",
    "cmake_minimum_required(VERSION 3.17)\n",
    "\n",
    "# Define the C++ standard for compilation. Although the examples are Fortran, the C++ library\n",
    "# they link against uses this standard.\n",
    "set(CMAKE_CXX_STANDARD 17)\n",
    "\n",
    "# Define the default build type if not specified by the user.\n",
    "if (NOT CMAKE_BUILD_TYPE)\n",
    "  set(CMAKE_BUILD_TYPE RelWithDebInfo)\n",
    "endif()\n",
    "\n",
    "# Apply a CMake policy. Kept from the parent CMakeLists.txt.\n",
    "cmake_policy(SET CMP0057 NEW)\n",
    "\n",
    "# --- User-Defined Build Options (from parent CMakeLists.txt) ---\n",
    "# We only keep the options relevant to the Fortran examples and their dependencies.\n",
    "# TORCHFORT_CUDA_CC_LIST: List of CUDA compute capabilities. Used to generate CUF_GPU_ARG.\n",
    "set(TORCHFORT_CUDA_CC_LIST \"70;80;90\" CACHE STRING \"List of CUDA compute capabilities for GPU compilation.\")\n",
    "# TORCHFORT_NCCL_ROOT: Path to find the NCCL installation. Required if using distributed MPI with GPU.\n",
    "set(TORCHFORT_NCCL_ROOT CACHE STRING \"Path to search for NCCL installation.\")\n",
    "# TORCHFORT_YAML_CPP_ROOT: Path to find the yaml-cpp installation. The C++ lib links against it.\n",
    "set(TORCHFORT_YAML_CPP_ROOT CACHE STRING \"Path to search for yaml-cpp installation.\")\n",
    "# TORCHFORT_ENABLE_GPU: Enable GPU/CUDA support. Affects CUDA/NCCL search and compilation options.\n",
    "option(TORCHFORT_ENABLE_GPU \"Enable GPU/CUDA support\" ON)\n",
    "# Options like BUILD_FORTRAN, BUILD_EXAMPLES, BUILD_TESTS are removed as this file ALREADY builds the Fortran examples.\n",
    "\n",
    "# Check if TORCHFORT_YAML_CPP_ROOT was defined, otherwise show fatal error (kept from parent).\n",
    "if (NOT TORCHFORT_YAML_CPP_ROOT)\n",
    "  message(FATAL_ERROR \"Please set TORCHFORT_YAML_CPP_ROOT to yaml-cpp installation directory.\")\n",
    "endif()\n",
    "\n",
    "# Define the project languages. We need Fortran for the examples and CXX for the library they link to.\n",
    "project(CombinedFortranExamples LANGUAGES Fortran CXX) # Project name changed to reflect content\n",
    "\n",
    "# --- External Dependency Search (from parent CMakeLists.txt and Fortran example) ---\n",
    "\n",
    "# MPI: Required for distributed examples.\n",
    "find_package(MPI REQUIRED)\n",
    "\n",
    "# HDF5: Required for data reading/writing in examples.\n",
    "find_package(HDF5 COMPONENTS Fortran REQUIRED)\n",
    "\n",
    "# CUDA and NCCL: Required if GPU support is enabled.\n",
    "if (TORCHFORT_ENABLE_GPU)\n",
    "  find_package(CUDAToolkit REQUIRED)\n",
    "\n",
    "  # Search for NVHPC compiler and CMake configurations (from parent).\n",
    "  find_program(NVHPC_CXX_BIN \"nvc++\")\n",
    "  if (NVHPC_CXX_BIN)\n",
    "    string(REPLACE \"compilers/bin/nvc++\" \"cmake\" NVHPC_CMAKE_DIR ${NVHPC_CXX_BIN})\n",
    "    # Add the NVHPC CMake directory to CMAKE_PREFIX_PATH to help find other NVHPC packages.\n",
    "    set(CMAKE_PREFIX_PATH \"${CMAKE_PREFIX_PATH};${NVHPC_CMAKE_DIR}\")\n",
    "    find_package(NVHPC COMPONENTS \"\") # Find the main NVHPC package.\n",
    "  endif()\n",
    "\n",
    "  # Search for the NCCL library (from parent). Uses TORCHFORT_NCCL_ROOT or NVHPC configurations.\n",
    "  if (TORCHFORT_NCCL_ROOT)\n",
    "    find_path(NCCL_INCLUDE_DIR REQUIRED\n",
    "      NAMES nccl.h\n",
    "      HINTS ${TORCHFORT_NCCL_ROOT}/include\n",
    "    )\n",
    "    find_library(NCCL_LIBRARY REQUIRED\n",
    "      NAMES nccl\n",
    "      HINTS ${TORCHFORT_NCCL_ROOT}/lib\n",
    "    )\n",
    "  else()\n",
    "    if (NVHPC_FOUND)\n",
    "      find_package(NVHPC REQUIRED COMPONENTS NCCL) # Try to find NCCL via NVHPC.\n",
    "      find_library(NCCL_LIBRARY\n",
    "        NAMES nccl\n",
    "        HINTS ${NVHPC_NCCL_LIBRARY_DIR} # NCCL directory provided by NVHPC.\n",
    "      )\n",
    "      # Derive the include directory from the NVHPC NCCL library directory.\n",
    "      string(REPLACE \"/lib\" \"/include\" NCCL_INCLUDE_DIR ${NVHPC_NCCL_LIBRARY_DIR})\n",
    "    else()\n",
    "      message(FATAL_ERROR \"Cannot find NCCL library. Please set TORCHFORT_NCCL_ROOT or ensure NVHPC is configured.\")\n",
    "    endif()\n",
    "  endif()\n",
    "  message(STATUS \"Using NCCL library: ${NCCL_LIBRARY}\")\n",
    "endif()\n",
    "\n",
    "# PyTorch: The internal library links against PyTorch/LibTorch.\n",
    "find_package(Torch REQUIRED)\n",
    "\n",
    "# yaml-cpp: The internal library links against yaml-cpp.\n",
    "# Use TORCHFORT_YAML_CPP_ROOT to find.\n",
    "find_path(YAML_CPP_INCLUDE_DIR REQUIRED\n",
    "  NAMES yaml-cpp/yaml.h\n",
    "  HINTS ${TORCHFORT_YAML_CPP_ROOT}/include\n",
    ")\n",
    "find_library(YAML_CPP_LIBRARY REQUIRED\n",
    "  NAMES yaml-cpp\n",
    "  HINTS ${TORCHFORT_YAML_CPP_ROOT}/lib\n",
    ")\n",
    "message(STATUS \"Using yaml-cpp library: ${YAML_CPP_LIBRARY}\")\n",
    "\n",
    "# --- Internal C++ Library Definition (from parent CMakeLists.txt) ---\n",
    "# The Fortran examples link against this library. We include all C++ sources\n",
    "# listed in the parent to ensure the library is built correctly.\n",
    "add_library(torchfort SHARED) # Keep the original target name that examples expect.\n",
    "set_target_properties(torchfort PROPERTIES LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib)\n",
    "\n",
    "# List of C++ source files (copy the necessary .cpp files to src/csrc/ relative to this CMakeLists.txt)\n",
    "target_sources(torchfort\n",
    "  PRIVATE\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/distributed.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/logging.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/model_state.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/model_wrapper.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/model_pack.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/param_map.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/setup.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/torchfort.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/training.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/utils.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/losses/l1_loss.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/losses/mse_loss.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/losses/torchscript_loss.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/lr_schedulers/cosine_annealing_lr.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/lr_schedulers/multistep_lr.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/lr_schedulers/polynomial_lr.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/lr_schedulers/scheduler_setup.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/lr_schedulers/step_lr.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/lr_schedulers/linear_lr.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/models/mlp_model.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/models/sac_model.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/models/actor_critic_model.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/rl/policy.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/rl/utils.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/rl/off_policy/interface.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/rl/off_policy/ddpg.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/rl/off_policy/td3.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/rl/off_policy/sac.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/rl/on_policy/interface.cpp\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/rl/on_policy/ppo.cpp\n",
    ")\n",
    "\n",
    "# Include directories for the C++ library (from parent).\n",
    "target_include_directories(torchfort\n",
    "  PRIVATE\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/include # Include the lib's own headers\n",
    "  ${YAML_CPP_INCLUDE_DIR} # Include yaml-cpp headers\n",
    "  ${MPI_CXX_INCLUDE_DIRS} # Include MPI C++ headers\n",
    "  ${TORCH_INCLUDE_DIRS} # Include PyTorch headers\n",
    ")\n",
    "if (TORCHFORT_ENABLE_GPU)\n",
    "  target_include_directories(torchfort\n",
    "    PRIVATE\n",
    "    ${CUDAToolkit_INCLUDE_DIRS} # Include CUDA Toolkit headers\n",
    "    ${NCCL_INCLUDE_DIR} # Include NCCL headers\n",
    "  )\n",
    "  target_link_libraries(torchfort PRIVATE CUDA::cudart) # Link against CUDA runtime\n",
    "  target_compile_definitions(torchfort PRIVATE ENABLE_GPU) # Define macro for GPU compilation\n",
    "endif()\n",
    "\n",
    "# Link the necessary libraries for the C++ library (from parent).\n",
    "target_link_libraries(torchfort PRIVATE ${TORCH_LIBRARIES})\n",
    "target_link_libraries(torchfort PRIVATE ${NCCL_LIBRARY})\n",
    "target_link_libraries(torchfort PRIVATE MPI::MPI_CXX) # Link against MPI C++ interface\n",
    "target_link_libraries(torchfort PRIVATE ${YAML_CPP_LIBRARY})\n",
    "\n",
    "# Compilation options for the C++ library (from parent).\n",
    "target_compile_definitions(torchfort PRIVATE YAML_CPP_STATIC_DEFINE)\n",
    "target_compile_options(torchfort PRIVATE $<$<COMPILE_LANGUAGE:CXX>:${TORCH_CXX_FLAGS}>)\n",
    "\n",
    "# Public headers for the C++ library (copy to src/csrc/include/ relative to this CMakeLists.txt)\n",
    "set(public_headers\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/include/torchfort.h\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/include/torchfort_rl.h\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/csrc/include/torchfort_enums.h\n",
    ")\n",
    "set_target_properties(\"torchfort\" PROPERTIES PUBLIC_HEADER \"${public_headers}\")\n",
    "\n",
    "# Installation rules for the C++ library (if you wish to install)\n",
    "install(\n",
    "  TARGETS torchfort\n",
    "  EXPORT \"torchfortTargets\"\n",
    "  PUBLIC_HEADER DESTINATION ${CMAKE_INSTALL_PREFIX}/include\n",
    "  INCLUDES DESTINATION ${CMAKE_INSTALL_PREFIX}/include # Install headers to include\n",
    "  RUNTIME DESTINATION ${CMAKE_INSTALL_PREFIX}/lib # Install the shared library to lib\n",
    ")\n",
    "\n",
    "\n",
    "# --- Fortran Library/Module Definition (from parent CMakeLists.txt) ---\n",
    "# The Fortran examples also link against this Fortran module/library.\n",
    "add_library(torchfort_fort SHARED) # Keep the original target name.\n",
    "set_target_properties(torchfort_fort PROPERTIES LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib)\n",
    "# Define where the Fortran compiler should put the module files (.mod).\n",
    "set_target_properties(torchfort_fort PROPERTIES Fortran_MODULE_DIRECTORY ${CMAKE_BINARY_DIR}/include) # Put .mod in CMAKE_BINARY_DIR/include\n",
    "\n",
    "# Fortran compilation options for the library (from parent).\n",
    "if (CMAKE_Fortran_COMPILER_ID STREQUAL \"NVHPC\")\n",
    "  # Create the -gpu argument string for GPU compilation with nvfortran (from parent).\n",
    "  # Depends on TORCHFORT_CUDA_CC_LIST and NVHPC_CUDA_VERSION.\n",
    "  set(CUF_GPU_ARG \"\") # Initialize the variable before using APPEND\n",
    "  foreach(CUDA_CC ${TORCHFORT_CUDA_CC_LIST})\n",
    "    list(APPEND CUF_GPU_ARG \"cc${CUDA_CC}\")\n",
    "  endforeach()\n",
    "  if (NVHPC_CUDA_VERSION) # Check if variable exists before using\n",
    "    list(APPEND CUF_GPU_ARG \"cuda${NVHPC_CUDA_VERSION}\")\n",
    "  endif()\n",
    "  list(JOIN CUF_GPU_ARG \",\" CUF_GPU_ARG)\n",
    "  message(STATUS \"Generated CUF_GPU_ARG: ${CUF_GPU_ARG}\") # Show the generated argument\n",
    "\n",
    "  target_compile_options(torchfort_fort PRIVATE $<$<COMPILE_LANGUAGE:Fortran>:-cpp -cuda -gpu=${CUF_GPU_ARG}>)\n",
    "elseif (CMAKE_Fortran_COMPILER_ID STREQUAL \"GNU\")\n",
    "  target_compile_options(torchfort_fort PRIVATE $<$<COMPILE_LANGUAGE:Fortran>:-cpp>)\n",
    "endif()\n",
    "\n",
    "# Test if MPI_Comm_f2c/c2f is available (from parent). Requires test_mpi_f2c.f90 file.\n",
    "try_compile(\n",
    "  TEST_F2C_RESULT\n",
    "  ${CMAKE_BINARY_DIR}\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/cmake/test_mpi_f2c.f90 # Path relative to the new CMakeLists.txt\n",
    "  LINK_LIBRARIES MPI::MPI_Fortran\n",
    ")\n",
    "if (NOT TEST_F2C_RESULT)\n",
    "  message(STATUS \"Could not link MPI_Comm_f2c in Fortran module. Setting -DMPICH flag during module compilation.\")\n",
    "  target_compile_definitions(torchfort_fort PRIVATE MPICH)\n",
    "endif()\n",
    "\n",
    "# Fortran source files for the library (copy torchfort_m.F90 to src/fsrc/ relative)\n",
    "target_sources(torchfort_fort\n",
    "  PRIVATE\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/src/fsrc/torchfort_m.F90\n",
    ")\n",
    "# Link the Fortran library against MPI Fortran (from parent).\n",
    "target_link_libraries(torchfort_fort PRIVATE MPI::MPI_Fortran)\n",
    "\n",
    "# Installation rules for the Fortran library and module (if you wish to install)\n",
    "install(\n",
    "  TARGETS torchfort_fort\n",
    "  RUNTIME DESTINATION ${CMAKE_INSTALL_PREFIX}/lib # Install the shared library to lib\n",
    ")\n",
    "# Install the Fortran module file (.mod) to the include directory.\n",
    "install(FILES ${CMAKE_BINARY_DIR}/include/torchfort.mod DESTINATION ${CMAKE_INSTALL_PREFIX}/include)\n",
    "\n",
    "\n",
    "# --- Fortran Example Executable Definitions (from the first CMakeLists.txt) ---\n",
    "\n",
    "# Add the 'train' executable target.\n",
    "add_executable(train)\n",
    "# Define the source code files (copy to examples/fortran/graph/ relative)\n",
    "target_sources(train\n",
    "  PRIVATE\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/examples/fortran/graph/train.f90\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/examples/fortran/graph/simulation.f90 # Assuming this is the copy used\n",
    ")\n",
    "# Define the directory for Fortran modules generated by this target.\n",
    "set_target_properties(train PROPERTIES Fortran_MODULE_DIRECTORY ${CMAKE_BINARY_DIR}/mod/train) # Put modules in a specific build dir\n",
    "\n",
    "\n",
    "# Add the 'train_distributed' executable target.\n",
    "add_executable(train_distributed)\n",
    "# Define the source code files (copy to examples/fortran/simulation/ relative)\n",
    "target_sources(train_distributed\n",
    "  PRIVATE\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/examples/fortran/simulation/train_distributed.f90\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/examples/fortran/simulation/simulation.f90 # Assuming this is the copy used\n",
    ")\n",
    "# Define the directory for Fortran modules generated by this target.\n",
    "set_target_properties(train_distributed PROPERTIES Fortran_MODULE_DIRECTORY ${CMAKE_BINARY_DIR}/mod/train_distributed) # Put modules in another specific build dir\n",
    "\n",
    "# List of executable targets for easier iteration or installation.\n",
    "set(fortran_example_targets train train_distributed)\n",
    "\n",
    "\n",
    "# --- Common Configurations for Executables (from the foreach loop in the first CMakeLists.txt) ---\n",
    "foreach(tgt ${fortran_example_targets})\n",
    "\n",
    "  # Define the include directories for the current target.\n",
    "  # Includes where to find generated Fortran modules (our BINAry_DIR/include),\n",
    "  # MPI Fortran headers, and HDF5 Fortran headers.\n",
    "  target_include_directories(${tgt}\n",
    "    PRIVATE\n",
    "    ${CMAKE_BINARY_DIR}/include # To find torchfort.mod and other generated modules\n",
    "    ${MPI_Fortran_INCLUDE_DIRS} # MPI headers for Fortran\n",
    "    ${HDF5_Fortran_INCLUDE_DIRS} # HDF5 headers for Fortran\n",
    "  )\n",
    "\n",
    "  # Specify the libraries against which the current target should be linked.\n",
    "  # Links against MPI Fortran, HDF5 Fortran, the internal Fortran library, and the internal C++ library.\n",
    "  target_link_libraries(${tgt} PRIVATE MPI::MPI_Fortran)\n",
    "  target_link_libraries(${tgt} PRIVATE hdf5::hdf5_fortran)\n",
    "  target_link_libraries(${tgt} PRIVATE torchfort_fort) # Link against the Fortran lib we defined above\n",
    "  target_link_libraries(${tgt} PRIVATE torchfort) # Link against the C++ lib we defined above\n",
    "\n",
    "  # Compiler-specific compilation/linking options (from the first CMakeLists.txt).\n",
    "  if (CMAKE_Fortran_COMPILER_ID STREQUAL \"NVHPC\")\n",
    "    # Use the previously generated CUF_GPU_ARG.\n",
    "    target_compile_options(${tgt} PRIVATE $<$<COMPILE_LANGUAGE:Fortran>:-cpp -acc -gpu=${CUF_GPU_ARG}>)\n",
    "    target_link_options(${tgt} PRIVATE $<$<COMPILE_LANGUAGE:Fortran>: -acc -gpu=${CUF_GPU_ARG}>)\n",
    "  elseif (CMAKE_Fortran_COMPILER_ID STREQUAL \"GNU\")\n",
    "    target_compile_options(${tgt} PRIVATE $<$<COMPILE_LANGUAGE:Fortran>:-cpp -fbackslash -fopenacc>)\n",
    "    target_link_options(${tgt} PRIVATE $<$<COMPILE_LANGUAGE:Fortran>: -fopenacc>)\n",
    "  endif()\n",
    "\n",
    "endforeach()\n",
    "\n",
    "\n",
    "# --- Installation Rules ---\n",
    "\n",
    "# Install the Fortran executables.\n",
    "install(\n",
    "  TARGETS ${fortran_example_targets}\n",
    "  # Define the destination directory relative to the installation prefix.\n",
    "  RUNTIME DESTINATION ${CMAKE_INSTALL_PREFIX}/bin/examples/fortran/simulation\n",
    ")\n",
    "\n",
    "# Install data files and Python scripts required for the examples.\n",
    "# (copy to examples/fortran/simulation/ relative to this CMakeLists.txt)\n",
    "install(\n",
    "  FILES\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/examples/fortran/simulation/config_mlp_native.yaml\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/examples/fortran/simulation/config_fcn_torchscript.yaml\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/examples/fortran/simulation/generate_fcn_model.py\n",
    "  ${CMAKE_CURRENT_SOURCE_DIR}/examples/fortran/simulation/visualize.py\n",
    "  # Define the destination directory, the same as the executables.\n",
    "  DESTINATION ${CMAKE_INSTALL_PREFIX}/bin/examples/fortran/simulation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62204a3-f746-4586-bf40-4a8aa06f2837",
   "metadata": {},
   "source": [
    "## repository/examples/fortran/simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eca6217-6473-41b5-9d12-644c5e011ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile CMakeLists.txt\n",
    "# Finds the HDF5 package, essential for reading and writing data in HDF5 format.\n",
    "# We specify that we need the Fortran component of HDF5.\n",
    "# The REQUIRED option ensures that the CMake configuration will fail if HDF5 (with Fortran support) is not found.\n",
    "find_package(HDF5 COMPONENTS Fortran REQUIRED)\n",
    "\n",
    "# Defines a list of Fortran executable targets that will be built.\n",
    "# In this case, we have two executables: 'train' and 'train_distributed'.\n",
    "set(fortran_example_targets\n",
    "  train\n",
    "  train_distributed\n",
    ")\n",
    "\n",
    "# Adds an executable target named 'train'.\n",
    "add_executable(train)\n",
    "# Defines the source code files that will be compiled to create the 'train' executable.\n",
    "# The PRIVATE keyword indicates that these files are specific to the build of this target\n",
    "# and should not be exposed to other targets that might link against it.\n",
    "target_sources(train\n",
    "  PRIVATE\n",
    "  train.f90\n",
    "  simulation.f90\n",
    ")\n",
    "\n",
    "# Sets specific properties for the 'train' target.\n",
    "# In this case, we are setting the directory where the Fortran modules generated during compilation\n",
    "# should be placed. ${CMAKE_CURRENT_SOURCE_DIR} represents the current directory of the CMakeLists.txt file.\n",
    "# 'mod/0' is the subdirectory within the source directory where the modules will be stored.\n",
    "set_target_properties(train PROPERTIES Fortran_MODULE_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/mod/0 )\n",
    "\n",
    "# Adds another executable target named 'train_distributed'.\n",
    "add_executable(train_distributed)\n",
    "\n",
    "# Defines the source code files for the 'train_distributed' executable.\n",
    "target_sources(train_distributed\n",
    "  PRIVATE\n",
    "  train_distributed.f90\n",
    "  simulation.f90\n",
    ")\n",
    "\n",
    "# Sets the properties for the 'train_distributed' target, similar to 'train',\n",
    "# but with a different Fortran module directory ('mod/1'). This can be useful to avoid\n",
    "# module name conflicts if the two executables have dependencies on modules with the same name.\n",
    "set_target_properties(train_distributed PROPERTIES Fortran_MODULE_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/mod/1 )\n",
    "\n",
    "# Starts a loop over each target listed in 'fortran_example_targets' ('train' and 'train_distributed').\n",
    "foreach(tgt ${fortran_example_targets})\n",
    "\n",
    "# Defines the include directories for the current target ($tgt).\n",
    "# PRIVATE means these directories are only needed during the compilation of this target.\n",
    "# ${CMAKE_BINARY_DIR}/include: Include directory within the CMake build directory.\n",
    "#                              May contain header files generated during the build process.\n",
    "# ${MPI_Fortran_INCLUDE_DIRS}: Include directories required to compile Fortran code that uses MPI (Message Passing Interface).\n",
    "#                               This variable is usually set by the FindMPI.cmake package.\n",
    "# ${HDF5_Fortran_INCLUDE_DIRS}: Include directories required to compile Fortran code that uses the HDF5 library.\n",
    "#                                This variable is set by the find_package(HDF5) we found earlier.\n",
    "  target_include_directories(${tgt}\n",
    "    PRIVATE\n",
    "    ${CMAKE_BINARY_DIR}/include\n",
    "    ${MPI_Fortran_INCLUDE_DIRS}\n",
    "    ${HDF5_Fortran_INCLUDE_DIRS}\n",
    "  )\n",
    "\n",
    "# Specifies the libraries that the current target ($tgt) should link against.\n",
    "# PRIVATE means these libraries are only needed for this target.\n",
    "# MPI::MPI_Fortran: Fortran interface of the MPI library (provided by the FindMPI package).\n",
    "# hdf5::hdf5_fortran: Fortran interface of the HDF5 library (provided by find_package(HDF5)).\n",
    "# \"${PROJECT_NAME}_fort\": An internal Fortran library of the project (name is derived from the project name).\n",
    "# ${PROJECT_NAME}: An internal C/C++ library of the project (name is the project name defined in the 'project(...)' command).\n",
    "  target_link_libraries(${tgt} PRIVATE MPI::MPI_Fortran)\n",
    "  target_link_libraries(${tgt} PRIVATE hdf5::hdf5_fortran)\n",
    "  target_link_libraries(${tgt} PRIVATE \"${PROJECT_NAME}_fort\")\n",
    "  target_link_libraries(${tgt} PRIVATE ${PROJECT_NAME})\n",
    "\n",
    "# Checks which Fortran compiler is being used.\n",
    "  if (CMAKE_Fortran_COMPILER_ID STREQUAL \"NVHPC\")\n",
    "\n",
    "# Defines specific compilation options for the NVHPC (NVIDIA HPC SDK) compiler.\n",
    "# $<$<COMPILE_LANGUAGE:Fortran>:...> applies options only when the compile language is Fortran.\n",
    "# -cpp: Enables the C preprocessor for Fortran files.\n",
    "# -acc: Enables OpenACC directives for parallel programming on GPUs.\n",
    "# -gpu=${CUF_GPU_ARG}: Passes a specific GPU argument (the CUF_GPU_ARG variable must be defined elsewhere).\n",
    "    target_compile_options(${tgt} PRIVATE $<$<COMPILE_LANGUAGE:Fortran>:-cpp -acc -gpu=${CUF_GPU_ARG}>)\n",
    "\n",
    "# Defines specific linking options for the NVHPC compiler.\n",
    "# The options are similar to the compile options, indicating that linking should also consider GPU acceleration.\n",
    "    target_link_options(${tgt} PRIVATE $<$<COMPILE_LANGUAGE:Fortran>: -acc -gpu=${CUF_GPU_ARG}>)\n",
    "\n",
    "# Otherwise, if the Fortran compiler is GNU gfortran.\n",
    "  elseif (CMAKE_Fortran_COMPILER_ID STREQUAL \"GNU\")\n",
    "\n",
    "# Defines specific compilation options for the GNU Fortran compiler.\n",
    "# -cpp: Enables the C preprocessor for Fortran files.\n",
    "# -fbackslash: Allows the use of backslashes to continue Fortran code lines (common in older code).\n",
    "# -fopenacc: Enables OpenACC support for parallel programming.\n",
    "    target_compile_options(${tgt} PRIVATE $<$<COMPILE_LANGUAGE:Fortran>:-cpp -fbackslash -fopenacc>)\n",
    "\n",
    "# Defines specific linking options for the GNU Fortran compiler.\n",
    "# -fopenacc: Ensures that OpenACC libraries are linked.\n",
    "    target_link_options(${tgt} PRIVATE $<$<COMPILE_LANGUAGE:Fortran>: -fopenacc>)\n",
    "  endif()\n",
    "\n",
    "# End of the foreach loop.\n",
    "endforeach()\n",
    "\n",
    "# Defines the installation rules for the Fortran executable targets.\n",
    "install(\n",
    "  TARGETS ${fortran_example_targets}\n",
    "\n",
    "# Specifies the destination directory for the executables during installation.\n",
    "# ${CMAKE_INSTALL_PREFIX} is a user-configurable installation prefix (usually /usr/local or /opt/...).\n",
    "# The executables will be placed in ${CMAKE_INSTALL_PREFIX}/bin/examples/fortran/simulation.\n",
    "  RUNTIME DESTINATION ${CMAKE_INSTALL_PREFIX}/bin/examples/fortran/simulation\n",
    ")\n",
    "\n",
    "# Defines the installation rules for data files and Python scripts.\n",
    "install(\n",
    "  FILES ${CMAKE_CURRENT_SOURCE_DIR}/config_mlp_native.yaml\n",
    "        ${CMAKE_CURRENT_SOURCE_DIR}/config_fcn_torchscript.yaml\n",
    "        ${CMAKE_CURRENT_SOURCE_DIR}/generate_fcn_model.py\n",
    "        ${CMAKE_CURRENT_SOURCE_DIR}/visualize.py\n",
    "\n",
    "# Specifies the destination directory for these files during installation,\n",
    "# in the same location as the Fortran executables.\n",
    "  DESTINATION ${CMAKE_INSTALL_PREFIX}/bin/examples/fortran/simulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02b5410-e5fa-4a72-852d-28f2fc29ff44",
   "metadata": {},
   "source": [
    "## Dockerfile.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e54d4f6-fbaf-43e0-82b7-ff22ce83ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Dockerfile.txt\n",
    "\n",
    "# Base image: Start from an NVIDIA CUDA development image.\n",
    "# This provides a base Ubuntu system with CUDA pre-installed, which is essential\n",
    "# for building a GPU-accelerated library like TorchFort.\n",
    "FROM nvcr.io/nvidia/cuda:12.3.1-devel-ubuntu22.04\n",
    "\n",
    "# Install System Dependencies\n",
    "# Set the DEBIAN_FRONTEND environment variable to noninteractive to prevent\n",
    "# prompts during package installation.\n",
    "ENV DEBIAN_FRONTEND noninteractive\n",
    "\n",
    "# Run an apt update and install core system dependencies.\n",
    "# curl, unzip, wget are for downloading files.\n",
    "# cmake is required to build TorchFort.\n",
    "# python3, python-is-python3, python3-pip are for Python support and package installation.\n",
    "# python3-pybind11 is specifically needed for the pybind11 C++ binding library.\n",
    "# git is needed to clone repositories (like NCCL, yaml-cpp, HDF5).\n",
    "# vim is a text editor (included in the base image for convenience).\n",
    "# gfortran is the GNU Fortran compiler (needed if not using NVHPC or for some dependencies).\n",
    "# doxygen is needed for building the documentation (though not built *in* this Dockerfile, it's listed as a dependency).\n",
    "# libibverbs-dev, ibverbs-utils, numactl are related to InfiniBand/networking, common in HPC environments, likely for MPI.\n",
    "RUN apt update -y && \\\n",
    "    apt install -y curl unzip wget cmake && \\\n",
    "    apt install -y python3 python-is-python3 python3-pip python3-pybind11 && \\\n",
    "    apt install -y git vim gfortran doxygen && \\\n",
    "    apt install -y libibverbs-dev ibverbs-utils numactl\n",
    "\n",
    "# Install NVHPC SDK\n",
    "# Download the NVIDIA HPC SDK installer.\n",
    "# The SDK includes NVHPC compilers (nvfortran, nvc++) and communication libraries (MPI, NCCL).\n",
    "RUN wget https://developer.download.nvidia.com/hpc-sdk/24.1/nvhpc_2024_241_Linux_x86_64_cuda_12.3.tar.gz && \\\n",
    "    # Extract the installer.\n",
    "    tar xpzf nvhpc_2024_241_Linux_x86_64_cuda_12.3.tar.gz && \\\n",
    "    # Run the installer silently.\n",
    "    nvhpc_2024_241_Linux_x86_64_cuda_12.3/install --quiet && \\\n",
    "    # Clean up the installer files.\n",
    "    rm -rf nvhpc_2024_241_Linux_x86_64_cuda_12.3 nvhpc_2024_241_Linux_x86_64_cuda_12.3.tar.gz\n",
    "\n",
    "# Set environment variables to include NVHPC binaries and libraries in the PATH and LD_LIBRARY_PATH.\n",
    "ENV PATH /opt/nvidia/hpc_sdk/Linux_x86_64/24.1/compilers/bin:$PATH\n",
    "ENV PATH /opt/nvidia/hpc_sdk/Linux_x86_64/24.1/comm_libs/mpi/bin:$PATH\n",
    "ENV LD_LIBRARY_PATH /opt/nvidia/hpc_sdk/Linux_x86_64/24.1/cuda/lib64:$LD_LIBRARY_PATH\n",
    "ENV LD_LIBRARY_PATH /opt/nvidia/hpc_sdk/Linux_x86_64/24.1/comm_libs/mpi/lib:$LD_LIBRARY_PATH\n",
    "ENV LD_LIBRARY_PATH /opt/nvidia/hpc_sdk/Linux_x86_64/24.1/comm_libs/nvshmem/lib:$LD_LIBRARY_PATH\n",
    "ENV LD_LIBRARY_PATH /opt/nvidia/hpc_sdk/Linux_x86_64/24.1/math_libs/lib64:$LD_LIBRARY_PATH\n",
    "\n",
    "# Set CUDA_HOME environment variable.\n",
    "ENV CUDA_HOME /opt/nvidia/hpc_sdk/Linux_x86_64/24.1/cuda\n",
    "\n",
    "# Configure HPCx (part of communication libs) initialization in .bashrc for interactive sessions.\n",
    "RUN echo \"source /opt/nvidia/hpc_sdk/Linux_x86_64/24.1/comm_libs/12.3/hpcx/latest/hpcx-init.sh; hpcx_load\" >> /root/.bashrc\n",
    "\n",
    "# Install newer NCCL for compatibility with PyTorch 2.2.1+\n",
    "# Change directory to /opt.\n",
    "RUN cd /opt && \\\n",
    "    # Clone the NCCL repository from GitHub, specifying a specific version tag.\n",
    "    git clone --branch v2.20.3-1 https://github.com/NVIDIA/nccl.git && \\\n",
    "    # Change into the cloned NCCL directory.\n",
    "    cd nccl && \\\n",
    "    # Build NCCL source, specifying CUDA compute capabilities and CUDA_HOME.\n",
    "    # The compute capabilities (70, 80, 90) are consistent with the default\n",
    "    # TORCHFORT_CUDA_CC_LIST in the main CMakeLists.txt.\n",
    "    make -j src.build NVCC_GENCODE=\"-gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_80,code=sm_80 -gencode=arch=compute_90,code=sm_90\" CUDA_HOME=/opt/nvidia/hpc_sdk/Linux_x86_64/24.1/cuda\n",
    "\n",
    "# Add the newly built NCCL library path to LD_LIBRARY_PATH.\n",
    "ENV LD_LIBRARY_PATH /opt/nccl/build/lib:$LD_LIBRARY_PATH\n",
    "\n",
    "# Install PyTorch\n",
    "# Use pip to install a specific version of PyTorch. This version is likely compatible\n",
    "# with the CUDA and NCCL versions installed.\n",
    "RUN pip3 install torch==2.4.0\n",
    "\n",
    "# Install yaml-cpp\n",
    "# Clone the yaml-cpp library from GitHub, specifying a specific version tag.\n",
    "RUN git clone https://github.com/jbeder/yaml-cpp.git --branch 0.8.0 && \\\n",
    "    # Change into the cloned directory.\n",
    "    cd yaml-cpp && \\\n",
    "    # Create and enter a build directory.\n",
    "    mkdir build && cd build && \\\n",
    "    # Configure the build using CMake.\n",
    "    # Set installation prefix to /opt/yaml-cpp.\n",
    "    # Set CXX flags, including -D_GLIBCXX_USE_CXX11_ABI=0 for ABI compatibility with PyTorch.\n",
    "    # Disable building shared libraries (BUILD_SHARED_LIBS=OFF), preferring static libs.\n",
    "    # Enable position-independent code (CMAKE_POSITION_INDEPENDENT_CODE=ON), good practice for libraries.\n",
    "    # '..' refers to the parent directory containing the CMakeLists.txt.\n",
    "    cmake -DCMAKE_INSTALL_PREFIX=/opt/yaml-cpp \\\n",
    "          -DCMAKE_CXX_FLAGS:=\"-D_GLIBCXX_USE_CXX11_ABI=0\" \\\n",
    "          -DBUILD_SHARED_LIBS=OFF \\\n",
    "          -DCMAKE_POSITION_INDEPENDENT_CODE=ON .. && \\\n",
    "    # Build the library using parallel jobs.\n",
    "    make -j$(nproc) && \\\n",
    "    # Install the built library.\n",
    "    make install\n",
    "\n",
    "# Add the installed yaml-cpp library path to LD_LIBRARY_PATH.\n",
    "ENV LD_LIBRARY_PATH /opt/yaml-cpp/lib:${LD_LIBRARY_PATH}\n",
    "\n",
    "# Install HDF5\n",
    "# Download the HDF5 source tarball.\n",
    "RUN wget https://github.com/HDFGroup/hdf5/archive/refs/tags/hdf5-1_14_3.tar.gz && \\\n",
    "    # Extract the tarball.\n",
    "    tar xzf hdf5-1_14_3.tar.gz && \\\n",
    "    # Change into the extracted source directory.\n",
    "    cd hdf5-hdf5-1_14_3 && \\\n",
    "    # Configure the build using the configure script.\n",
    "    # Set C and Fortran compilers to mpicc and mpifort (MPI wrappers from NVHPC SDK).\n",
    "    # Set Fortran and C flags to -fPIC for position-independent code.\n",
    "    # Enable parallel HDF5 support (--enable-parallel).\n",
    "    # Enable Fortran bindings (--enable-fortran).\n",
    "    # Set installation prefix to /opt/hdf5.\n",
    "    CC=mpicc FC=mpifort FCFLAGS=-fPIC CFLAGS=-fPIC \\\n",
    "    ./configure --enable-parallel \\\n",
    "                --enable-fortran \\\n",
    "                --prefix=/opt/hdf5 && \\\n",
    "    # Build and install using parallel jobs.\n",
    "    make -j$(nproc) install && \\\n",
    "    # Change back to the parent directory.\n",
    "    cd .. && \\\n",
    "    # Clean up source and tarball files.\n",
    "    rm -rf hdf5-hdf5-1_14_3 hdf5-1_14_3.tar.gz\n",
    "\n",
    "# Add the installed HDF5 library path to LD_LIBRARY_PATH.\n",
    "ENV LD_LIBRARY_PATH /opt/hdf5/lib:$LD_LIBRARY_PATH\n",
    "\n",
    "# Install additional Python dependencies\n",
    "# Install Python packages required by TorchFort and its examples/docs using pip.\n",
    "RUN pip3 install wandb ruamel-yaml h5py matplotlib pygame moviepy\n",
    "\n",
    "# Install TorchFort\n",
    "# Set the Fortran compiler environment variable.\n",
    "ENV FC=nvfortran\n",
    "# Set the HDF5_ROOT environment variable, used by TorchFort's CMake to find HDF5.\n",
    "ENV HDF5_ROOT=/opt/hdf5\n",
    "\n",
    "# Copy the entire TorchFort source code from the build context into the /torchfort directory in the container.\n",
    "COPY . /torchfort\n",
    "\n",
    "# Build TorchFort inside the container.\n",
    "# Change into the /torchfort directory.\n",
    "RUN cd /torchfort && \\\n",
    "    # Create and enter a build directory.\n",
    "    mkdir build && cd build && \\\n",
    "    # Run CMake configuration.\n",
    "    # Set CUDA_PATH environment variable.\n",
    "    # Set the installation prefix to /opt/torchfort.\n",
    "    # Explicitly set the C++ compiler to g++ (as nvc++ is not supported for C++ files).\n",
    "    # Point CMake to the installed yaml-cpp root.\n",
    "    # Point CMake to the built NCCL root.\n",
    "    # Enable building examples.\n",
    "    # Enable building tests.\n",
    "    # Set CMAKE_PREFIX_PATH to include the PyTorch installation path, found using a Python command.\n",
    "    # '..' refers to the parent directory containing the root CMakeLists.txt.\n",
    "    CUDA_PATH=/opt/nvidia/hpc_sdk/Linux_x86_64/24.1/cuda \\\n",
    "    cmake -DCMAKE_INSTALL_PREFIX=/opt/torchfort \\\n",
    "          -DCMAKE_CXX_COMPILER=`which g++` \\\n",
    "          -DTORCHFORT_YAML_CPP_ROOT=/opt/yaml-cpp \\\n",
    "          -DTORCHFORT_NCCL_ROOT=/opt/nccl/build \\\n",
    "          -DTORCHFORT_BUILD_EXAMPLES=1 \\\n",
    "          -DTORCHFORT_BUILD_TESTS=1 \\\n",
    "          -DCMAKE_PREFIX_PATH=\"`python -c 'import torch;print(torch.utils.cmake_prefix_path)'`\" \\\n",
    "          .. && \\\n",
    "    # Build and install TorchFort using parallel jobs.\n",
    "    make -j$(nproc) install && \\\n",
    "    # Optional: Clean up the build directory after installation (commented out in source).\n",
    "    #cd / && rm -rf torchfort\n",
    "    : # This colon is a placeholder for the commented out line above\n",
    "   \n",
    "\n",
    "# Add the installed TorchFort library path to LD_LIBRARY_PATH.\n",
    "ENV LD_LIBRARY_PATH /opt/torchfort/lib:${LD_LIBRARY_PATH}\n",
    "# Add the PyTorch library path to LD_LIBRARY_PATH. The specific path is for Python 3.10 on Ubuntu 22.04.\n",
    "ENV LD_LIBRARY_PATH /usr/local/lib/python3.10/dist-packages/torch/lib:${LD_LIBRARY_PATH}\n",
    "\n",
    "# Set the default command to run when the container starts.\n",
    "# This starts a bash shell, keeping the container running and allowing interaction.\n",
    "ENTRYPOINT bash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fed943-1af1-40f1-b8a4-191b631e7f31",
   "metadata": {},
   "source": [
    "This Dockerfile defines a multi-stage process within a single file (though it's not explicitly labeled as multi-stage, the process of installing dependencies and then building the main project inside is typical). It starts with a base CUDA image, installs numerous system libraries and tools, downloads and builds core dependencies like NVHPC SDK, NCCL, yaml-cpp, and HDF5, installs PyTorch via pip, and finally copies the TorchFort source code into the container and builds and installs it.\n",
    "\n",
    "The use of environment variables like `PATH`, `LD_LIBRARY_PATH`, `FC`, and `HDF5_ROOT`, as well as specific CMake flags like `-DCMAKE_CXX_COMPILER`, `-DTORCHFORT_YAML_CPP_ROOT`, `-DTORCHFORT_NCCL_ROOT`, `-DTORCHFORT_BUILD_EXAMPLES`, and `-DTORCHFORT_BUILD_TESTS`, are crucial for correctly configuring the build process within the container environment, ensuring that TorchFort finds all its dependencies and is built with the desired features (like examples and tests) enabled. The Dockerfile also specifies the use of the NVHPC compilers for Fortran (`nvfortran`) and GNU (`g++`) for C++, as required by the main `CMakeLists.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b245b5af-2992-476f-823f-20b89f9639b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
